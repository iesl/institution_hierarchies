{
    "grid_search_fields": ["fold"],
    "model_name": "TokenSim",
    "tokenizer_name": "Unigram",
    "vocab_file": "data/ancestors/vocab",
    "train_file": "data/ancestors/train.txt",
    "dev_file": "data/ancestors/dev.txt",
    "test_file": "data/ancestors/test.txt",
    "inst_tokenizer_name": "Unigram",
    "city_tokenizer_name": "Unigram",
    "state_tokenizer_name": "Char",
    "country_tokenizer_name": "Char",
    "type_tokenizer_name": "Char",
    "include_city": "True",
    "include_state": "True",
    "include_country": "True",
    "include_type": "True",
    "fold": [0, 1, 2, 3, 4],
    "codec": "utf-8" 
}
